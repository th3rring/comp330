{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "# this matrix will store the data\n",
    "labels = np.array (1)\n",
    " \n",
    "# and this vector will store the labels\n",
    "points = np.array (1)\n",
    " \n",
    "# open up the input text file\n",
    "with open('bc.txt') as f:\n",
    "     # \n",
    "     # read in the lines and init the data and labels\n",
    "    lines = f.readlines ()\n",
    "    labels = np.zeros (len (lines))\n",
    "    points = np.zeros ((len (lines), 30))\n",
    "    counter = 0\n",
    "    #\n",
    "    # loop through each of the lines\n",
    "    for line in lines:\n",
    "        #\n",
    "        # get all of the items on the line\n",
    "        array = [x for x in line.split (',')]\n",
    "        #\n",
    "        # get the data point\n",
    "        for index in range (2, 32):\n",
    "            points[counter,index - 2] = float (array[index])\n",
    "            #\n",
    "            # if cancerous, 1, else -1\n",
    "        if (array[1] == 'M'):\n",
    "            labels [counter] = 1\n",
    "        else:\n",
    "            labels [counter] = -1\n",
    "        counter = counter + 1\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates the loss function and returns the loss\n",
    "#\n",
    "# x is the data set\n",
    "# y is the labels\n",
    "# w is the current set of weights\n",
    "# c is the weight of the slack variables\n",
    "#\n",
    "def f (x, y, w, c):\n",
    "    loss = 0\n",
    "    # fill in missing code here!!\n",
    "    n = x.shape[0]\n",
    "    lmd = 1/(n*c)\n",
    "    \n",
    "    loss = lmd/2 * np.linalg.norm(w)**2\n",
    "\n",
    "    for i in range(n):\n",
    "        loss += max(0, 1-y[i]*(np.dot(w,x[i])))/float(n)\n",
    "        \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates and returns the gradient \n",
    "#\n",
    "# x is the data set\n",
    "# y is the labels\n",
    "# w is the current set of weights\n",
    "# c is the weight of the slack variables\n",
    "#\n",
    "def gradient(x, y, w, c):\n",
    "    # Note that the gradient has 30 dims because the data has 30 dims\n",
    "    gradient = np.zeros (30)\n",
    "    n = x.shape[0]\n",
    "    lmd = 1/(n*c)\n",
    "    \n",
    "    for j in range(gradient.shape[0]):\n",
    "        gradient[j] += lmd*w[j]\n",
    "        \n",
    "        for i in range(x.shape[0]):\n",
    "            if(1-y[i]*(np.dot(x[i],w)) >= 0):\n",
    "                gradient[j] += -y[i]*x[i][j]/float(n)\n",
    "        \n",
    "    \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions using all of the data points in x\n",
    "# print ‘success’ or ‘failure’ depending on whether the \n",
    "# prediction is correct \n",
    "#\n",
    "# x is the data set\n",
    "# y is the labels\n",
    "# w is the current set of weights\n",
    "#\n",
    "def predict (x, y, w):\n",
    "    correct = 0;\n",
    "    pred_true_act_true = 0.0\n",
    "    act_true = 0.0\n",
    "    pred_true = 0.0\n",
    "    \n",
    "    for index in range (len (y)):\n",
    "        \n",
    "        if ((np.dot (x[index], w) > 0) and (y[index] > 0)):\n",
    "            print ('success')\n",
    "            correct = correct + 1\n",
    "            pred_true_act_true += 1\n",
    "        elif ((np.dot (x[index], w) < 0) and (y[index] < 0)):\n",
    "            print ('success')\n",
    "            correct = correct + 1\n",
    "        else:\n",
    "               print ('failure')\n",
    "                \n",
    "        if (y[index] > 0):\n",
    "            act_true += 1\n",
    "        if (np.dot (x[index], w) > 0):\n",
    "            pred_true += 1\n",
    "        \n",
    "                \n",
    "        recall = pred_true_act_true/act_true\n",
    "        prec = pred_true_act_true/pred_true\n",
    "        f1 = (2*prec * recall)/(recall + prec)\n",
    "    print ('%d out of %d correct. recall = %f, precision = %f, F1 = %f' % (correct, len(y), \n",
    "                                                                           recall, \n",
    "                                                                           prec,\n",
    "                                                                           f1))        \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performs gradient descent optimization, returns the learned set of weights\n",
    "# uses the bold driver to set the learning rate\n",
    "#\n",
    "# x is the data set\n",
    "# y is the labels\n",
    "# w is the current set of weights  to start with\n",
    "# c is the weight of the slack variable\n",
    "#\n",
    "def gd_optimize (x, y, w, c):\n",
    "    rate = 1\n",
    "    w_last = w + np.full (30, 1.0) \n",
    "    while (abs(f (x, y, w, c) - f (x, y, w_last, c)) > 10e-4):\n",
    "        w_last = w \n",
    "        w = w - rate * gradient (x, y, w, c)\n",
    "        if f (x, y, w, c) > f (x, y, w_last, c):\n",
    "             rate = rate * .5\n",
    "        else:\n",
    "            rate = rate * 1.1\n",
    "        print (f (x, y, w, c))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69700302.4928069\n",
      "27139886593982.418\n",
      "2.633444334346831e+18\n",
      "6.347275667025565e+22\n",
      "3.775528166265502e+26\n",
      "5.4698111790343736e+29\n",
      "1.878372686812761e+32\n",
      "1.4432698495273406e+34\n",
      "2.1759072403680355e+35\n",
      "4.520777980892215e+35\n",
      "2.2020650496678434e+34\n",
      "2.58728614982727e+33\n",
      "5.888079789420316e+32\n",
      "2.29823461934942e+32\n",
      "1.4242926362623193e+32\n",
      "1.3289622655785738e+32\n",
      "1.7961225577802806e+32\n",
      "1.1864520321238467e+30\n",
      "4.256197006633695e+28\n",
      "4.0465907828139344e+27\n",
      "7.80492217875949e+26\n",
      "2.653669661140718e+26\n",
      "1.4586697933408999e+26\n",
      "1.2226891566076535e+26\n",
      "1.4986115642275158e+26\n",
      "4.297352440880789e+23\n",
      "1.0851092927381926e+22\n",
      "8.193907416367959e+20\n",
      "1.3259770240993814e+20\n",
      "3.9024608781571826e+19\n",
      "1.8945023461648302e+19\n",
      "1.4221959229232775e+19\n",
      "1.577153482584927e+19\n",
      "1.1104862749277618e+16\n",
      "185337177339582.22\n",
      "10863870113379.312\n",
      "1457866075769.581\n",
      "368807266849.61206\n",
      "157398667388.41367\n",
      "105480587164.9247\n",
      "105585242018.21518\n",
      "8239.560138139119\n",
      "964.9725939395673\n",
      "665.0230527570304\n",
      "1009.3836503315612\n",
      "53.344066528265806\n",
      "183.11748242923403\n",
      "38.47202921249457\n",
      "65.31425499660887\n",
      "23.69310518503633\n",
      "23.875113228873804\n",
      "16.471859453431275\n",
      "5.297027304106107\n",
      "33.51123667656797\n",
      "20.49502397238413\n",
      "8.074746018957693\n",
      "7.130772121650521\n",
      "19.49101557768866\n",
      "11.950724564153083\n",
      "4.396856442147103\n",
      "6.182660988524772\n",
      "3.5211517514764905\n",
      "1.6989861876999828\n",
      "6.320155064528963\n",
      "3.946731818318454\n",
      "1.4251441525877575\n",
      "2.761748116113873\n",
      "1.086957008016784\n",
      "1.1190124151511553\n",
      "0.8099892483507372\n",
      "0.7607346111138732\n",
      "0.7937708986202981\n",
      "0.6835595593246578\n",
      "0.6820416515594775\n",
      "0.6804139820411049\n",
      "0.6786820846557341\n",
      "0.6767818768266465\n",
      "0.6747296231747127\n",
      "0.6724912951454247\n",
      "0.670085452943052\n",
      "0.6678022230186274\n",
      "0.6647054228562542\n",
      "0.6622322234694376\n",
      "0.6604700057982914\n",
      "0.6804784032670221\n",
      "0.6763088815979653\n",
      "0.6846162578936155\n",
      "0.6508305188024478\n",
      "0.649817166295569\n",
      "0.6487698656328288\n",
      "0.647632010932167\n",
      "0.646443404005689\n",
      "0.645022295140249\n",
      "0.6436501281080856\n",
      "0.6423885620207385\n",
      "0.6407684736961153\n",
      "0.6397716258279191\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "failure\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "failure\n",
      "success\n",
      "failure\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "failure\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "failure\n",
      "success\n",
      "failure\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "failure\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "failure\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "failure\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "failure\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "failure\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "158 out of 169 correct. recall = 0.743590, precision = 0.966667, F1 = 0.840580\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros (30)\n",
    "\n",
    "w = gd_optimize (points[0:400], labels[0:400], w, .000002)\n",
    "\n",
    "predict (points[400:], labels[400:], w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
